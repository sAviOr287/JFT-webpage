<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Jean-François Ton · Research Scientist</title>
    <meta
      name="description"
      content="Jean-François Ton is a senior research scientist advancing post-training, reward modelling, and multi-agent systems for large language models."
    />
    <link rel="shortcut icon" href="Images/favicon.ico" type="image/x-icon" />
    <link rel="stylesheet" href="css/font-raleway.css" />
    <link rel="stylesheet" href="css/base.css" />
    <link rel="stylesheet" href="css/layout.css" />
    <link rel="stylesheet" href="css/theme.css" />
  </head>
  <body>
    <header class="site-header">
      <div class="container nav-container">
        <a class="brand" href="index.html">Jean-François Ton</a>
        <button class="nav-toggle" aria-expanded="false" aria-controls="site-navigation">
          <span class="visually-hidden">Toggle navigation</span>
          <span></span>
          <span></span>
          <span></span>
        </button>
        <nav id="site-navigation" class="site-navigation" data-open="false">
          <ul>
            <li><a href="index.html" aria-current="page">Home</a></li>
            <li><a href="works.html">Research</a></li>
            <li><a href="contact.html">Contact</a></li>
          </ul>
        </nav>
      </div>
    </header>

    <main>
      <section class="hero">
        <div class="container hero__content">
          <div>
            <span class="hero-badge" data-reveal>
              <svg aria-hidden="true" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path
                  d="M20 6.5L9.5 17L4 11.5"
                  stroke="currentColor"
                  stroke-width="1.8"
                  stroke-linecap="round"
                  stroke-linejoin="round"
                />
              </svg>
              Aligning LLMs responsibly
            </span>
            <h1 class="hero__headline" data-reveal>
              Architecting post-training systems for aligned large language models
            </h1>
            <p class="hero__copy" data-reveal>
              I am a senior research scientist driving the post-training roadmap for frontier assistants at TikTok.
              My team delivers reinforcement learning from human feedback, preference modelling, and multi-agent
              collaboration frameworks that keep language models helpful, honest, and grounded in human intent. Prior to
              this LLM-focused chapter, I worked extensively on kernels, causality, and conformal prediction—statistical
              foundations that still inform how I measure and improve alignment today.
            </p>
            <div class="hero__actions" data-reveal>
              <a class="button" href="#recent-work">Explore recent work</a>
              <a class="button button--ghost" href="works.html">View full publications</a>
            </div>
          </div>
          <figure class="hero__portrait" data-reveal>
            <img src="Images/me_photo2.jpg" alt="Portrait of Jean-François Ton" />
          </figure>
        </div>
      </section>

      <section class="section" id="focus">
        <div class="container">
          <div class="section__header" data-reveal>
            <span class="section__eyebrow">Research focus</span>
            <h2 class="section__title">From post-training protocols to multi-agent systems</h2>
            <p class="section__description">
              My current agenda centres on ensuring large language models internalise the right behaviours after
              pre-training. That means aligning models with nuanced policy guidelines, building resilient reward models,
              and leveraging collectives of agents to stress-test reasoning. These pillars build on years spent in
              statistical machine learning and causal inference.
            </p>
          </div>
          <div class="focus__grid">
            <article class="focus-card" data-reveal>
              <h3>Post-training & RLHF</h3>
              <p>
                Designing scalable pipelines that transform base models into responsible assistants using instruction
                tuning, direct preference optimisation, and reinforcement learning from human feedback.
              </p>
            </article>
            <article class="focus-card" data-reveal>
              <h3>Reward modelling</h3>
              <p>
                Crafting preference-based objectives that capture subtle trade-offs between helpfulness, safety, and
                controllability across open-domain dialogue and task-oriented agents.
              </p>
            </article>
            <article class="focus-card" data-reveal>
              <h3>Multi-agent evaluation</h3>
              <p>
                Studying debate, critique, and collaboration between aligned agents to expose model blind spots and
                improve collective reasoning under sparse supervision.
              </p>
            </article>
            <article class="focus-card" data-reveal>
              <h3>Statistical foundations</h3>
              <p>
                Earlier work on kernels, causality, and conformal prediction informs the measurement science behind our
                alignment metrics and safety guarantees.
              </p>
            </article>
          </div>
        </div>
      </section>

      <section class="section" id="recent-work">
        <div class="container">
          <div class="section__header" data-reveal>
            <span class="section__eyebrow">Latest research</span>
            <h2 class="section__title">Recent highlights</h2>
            <p class="section__description">
              Scroll through the newest publications and launch announcements from the lab. Cards reveal as you move down
              the page for a focused reading experience.
            </p>
          </div>
          <div class="cards-grid" data-role="papers-list" data-view="latest" data-limit="4"></div>
          <div class="section__description" data-reveal>
            Looking for earlier work in kernels, causality, or conformal prediction?&nbsp;
            <a class="link-arrow" href="works.html">
              Browse the full archive
              <svg aria-hidden="true" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none">
                <path d="M5 12h14M13 6l6 6-6 6" stroke="currentColor" stroke-width="1.8" stroke-linecap="round" />
              </svg>
            </a>
          </div>
        </div>
      </section>

      <section class="section">
        <div class="container">
          <div class="section__header" data-reveal>
            <span class="section__eyebrow">Trajectory</span>
            <h2 class="section__title">A research career rooted in rigorous machine learning</h2>
            <p class="section__description">
              The journey from Oxford statistics to industry-scale LLM alignment has been anchored by collaboration with
              world-class teams across academia and product labs.
            </p>
          </div>
          <div class="timeline">
            <article class="timeline__item" data-reveal>
              <time datetime="2022">2022—Present</time>
              <h3>Senior Research Scientist, TikTok Applied AI Lab</h3>
              <p>
                Leading the post-training group responsible for RLHF, reward models, and multi-agent evaluation tooling
                across consumer-facing assistants and creator experiences.
              </p>
            </article>
            <article class="timeline__item" data-reveal>
              <time datetime="2021">2021</time>
              <h3>DPhil in Machine Learning, University of Oxford</h3>
              <p>
                Supervised by Professors Yee Whye Teh and Dino Sejdinovic, exploring causal uncertainty quantification,
                kernel methods, and conformal inference.
              </p>
            </article>
            <article class="timeline__item" data-reveal>
              <time datetime="2019">Industry experiences</time>
              <p>
                Applied research stints at Amazon Tübingen, Apple AI/ML, and Bloomberg LP honed my focus on deployable
                machine learning systems.
              </p>
            </article>
          </div>
        </div>
      </section>

      <section class="callout" id="collaborate">
        <div class="container" data-reveal>
          <h2>Collaborate on alignment research</h2>
          <p>
            I am not currently hiring interns, but I regularly partner with academic groups and industry labs on
            evaluation, safety, and human-feedback projects. If you have a collaboration idea, feel free to reach out.
          </p>
          <a class="button button--ghost" href="contact.html">Get in touch</a>
        </div>
      </section>
    </main>

    <footer class="site-footer">
      <div class="container site-footer__content">
        <span>© Jean-François Ton</span>
        <div class="social-links" aria-label="External profiles">
          <a href="https://github.com/sAviOr287" target="_blank" rel="noopener">
            <svg aria-hidden="true" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" fill="none">
              <path
                d="M12 2.25c-5.385 0-9.75 4.365-9.75 9.75 0 4.302 2.79 7.952 6.66 9.24.486.09.664-.21.664-.47 0-.23-.008-.84-.013-1.65-2.706.59-3.276-1.303-3.276-1.303-.443-1.125-1.082-1.425-1.082-1.425-.885-.606.067-.594.067-.594.978.07 1.493 1.005 1.493 1.005.87 1.49 2.285 1.06 2.84.81.09-.63.34-1.06.62-1.305-2.16-.246-4.432-1.08-4.432-4.81 0-1.062.38-1.932 1.003-2.61-.1-.247-.435-1.24.096-2.585 0 0 .813-.26 2.664.996A9.28 9.28 0 0 1 12 6.84a9.28 9.28 0 0 1 2.424.33c1.85-1.255 2.662-.996 2.662-.996.533 1.345.198 2.338.097 2.585.624.678 1.002 1.548 1.002 2.61 0 3.74-2.276 4.56-4.444 4.8.35.3.66.89.66 1.79 0 1.29-.012 2.33-.012 2.65 0 .26.176.566.668.468 3.868-1.29 6.656-4.94 6.656-9.24 0-5.385-4.365-9.75-9.75-9.75Z"
                fill="currentColor"
              />
            </svg>
            <span class="visually-hidden">GitHub</span>
          </a>
          <a href="https://www.linkedin.com/in/jean-fran%C3%A7ois-ton-b172a5102/" target="_blank" rel="noopener">
            <svg aria-hidden="true" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" fill="none">
              <path
                d="M20.447 20.452h-3.554v-5.568c0-1.328-.026-3.038-1.852-3.038-1.853 0-2.136 1.447-2.136 2.942v5.664H9.35V9h3.414v1.561h.049c.476-.9 1.637-1.852 3.368-1.852 3.603 0 4.268 2.371 4.268 5.455v6.288ZM5.337 7.433a2.062 2.062 0 1 1 0-4.124 2.062 2.062 0 0 1 0 4.124Zm-1.778 13.02h3.558V9h-3.558v11.453Z"
                fill="currentColor"
              />
            </svg>
            <span class="visually-hidden">LinkedIn</span>
          </a>
          <a href="https://scholar.google.com/citations?user=WWVOu4kAAAAJ&hl=en" target="_blank" rel="noopener">
            <svg aria-hidden="true" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none">
              <path
                d="M4.5 10.5 12 4.5l7.5 6-7.5 6-7.5-6Zm0 3.75L12 21l7.5-6.75"
                stroke="currentColor"
                stroke-width="1.6"
                stroke-linecap="round"
                stroke-linejoin="round"
              />
            </svg>
            <span class="visually-hidden">Google Scholar</span>
          </a>
        </div>
      </div>
    </footer>

    <script src="js/navigation.js" defer></script>
    <script src="js/papers.js" defer></script>
    <script src="js/reveal.js" defer></script>
  </body>
</html>
